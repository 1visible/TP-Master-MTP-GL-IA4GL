{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "from git import Repo, Git\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fonction permettant de supprimer des colonnes dans un dataframe Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delete_unused_columns(df):\n",
    "    columns_to_drop = [\"name\", \"followers\", \"commit_count_a\", \"source\", \"job\", \"name_without_spaces\", \"from\", \"to\",\n",
    "                       \"project\", \"index\", \"AddSM\",\"DelSM\",\"ChurnSM\",\"SumAddDelSM\",\"SumAddDel\"]\n",
    "\n",
    "    for column_to_drop in columns_to_drop:\n",
    "        if column_to_drop in df.columns :\n",
    "            df.drop(columns=[column_to_drop], inplace=True)\n",
    "\n",
    "    df[\"DiP\"] = df[\"DiP\"].round()\n",
    "    df[\"DiP\"].replace(0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant d'appliquer un logarithme sur des colonnes d'un dataframe Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_dataframe(df):\n",
    "\n",
    "    columns_4_log = [\"SumAddDelLOC\", \"DiP\", \"NoC\", \"SumAddDelF\",\n",
    "                     \"SumAddDelSAM\", \"AddLOC\", \"DelLOC\", \"AddSAM\", \"DelSAM\"]\n",
    "\n",
    "    for column in columns_4_log:\n",
    "        df[column] = np.log(df[column] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scores the classifier using a k-fold (here a Stratified 4-fold with shuffle)\n",
    "Synthetic data are created to train the classifier for each fold.\n",
    "Real data are used to compute measures for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Récupération des métriques de BroadleafCommerce\n",
    "\n",
    "Nous travaillerons avec les versions majeures et mineures (voir [semantic versioning](https://semver.org/lang/fr/)) du projet BroadleafCommerce disponible sur GitHub : [https://github.com/BroadleafCommerce/BroadleafCommerce](https://github.com/BroadleafCommerce/BroadleafCommerce). Pour cela, nous allons cloner le dépôt puis récupérer les tags des versions et les filtrer par une expression régulière. Puis, pour chacun de ces tags, \"checkouter\" la version correspondante. Nous lancerons ensuite l'extraction des métriques à l'aide de l'application Java : ck ([https://github.com/mauricioaniche/ck](https://github.com/mauricioaniche/ck)). Cette application créée par Maurício Aniche est dédiée à l'extraction de plusieurs métriques logicielles dont le nombre de lignes de code que nous utiliserons plus tard. \n",
    "\n",
    "Dans ce TP, nous allons extraire \"manuellement\" métriques mais, les plateformes d'intégration continue comme Jenkins ou les outils d'analyse statique comme SonarQube permettent également de calculer des métriques de manière automatique à chaque version releasée ou commitée sur votre système de gestion de versions. \n",
    "\n",
    "\n",
    "Pour notre cas d'étude, nous allons : \n",
    "\n",
    "1. Utiliser le package GitPython et sa [documentation](https://gitpython.readthedocs.io/en/stable/)) pour :\n",
    "\n",
    "* Cloner le dépôt Github de BroadleafCommerce à l'endroit indiqué par la variable <code> PATH_TO_REPO </code> à l'aide de la méthode <code> Repo.clone_from </code>\n",
    "* Créer un objet <code> Repo </code> qui vous permettra de récupérer les tags des versions\n",
    "* Créer un objet <code> Git </code> qui vous permettra de \"checkouter\" la version désirée\n",
    "\n",
    "2. Récupérer la liste des tags du dépôt à l'aide de l'objet <code> Repo </code>.\n",
    "\n",
    "3. Itérer sur la liste des tags, où pour chaque tag vous allez : \n",
    "\n",
    "* Vérifier par une regexp que l'on se situe sur des tags ayant la forme <code> broadleaf-X-Y-0-GA </code> où <code> X </code> et <code> Y </code> peuvent varier entre 0 et 9 et où le tag a une taille fixe (utilisation de ^ et $ pour matérialiser le début et la fin de chaine de caractères)\n",
    "* Vérifier que l'on ne va pas extraire les métriques d'une version déjà présente dans le dossier <code> ck_metrics </code>\n",
    "* **/!\\ Une fois ces vérifications effectuées,** checkouter la version désirée à l'aide du tag\n",
    "* Lancer l'extraction des métriques à l'aide de l'instruction python suivante : <code> subprocess.run([\"java\", \"-jar\", \"ck.jar\", \"..\" + os.sep + \"BroadleafCommerce\"]) </code>\n",
    "* Renommer le fichier <code> class.csv </code> en <code> class_[tag].csv </code> et supprimer les fichiers <code> variable.csv, methode.csv, field.csv </code> créés par ck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_REPO = \".\"+os.sep+\"BroadleafCommerce\"\n",
    "\n",
    "#Créer les objets Git et repo ici avant l'instruction change directory\n",
    "if not os.path.isdir(PATH_TO_REPO):\n",
    "    repo = Repo.clone_from(url=\"https://github.com/BroadleafCommerce/BroadleafCommerce.git\", to_path=PATH_TO_REPO, branch=\"master\")\n",
    "else:\n",
    "    repo = Repo(PATH_TO_REPO)\n",
    "\n",
    "git = Git(PATH_TO_REPO)\n",
    "\n",
    "wd_notebook = os.getcwd()\n",
    "os.chdir(\".\" + os.sep + \"ck_metrics\")\n",
    "\n",
    "#Placer l'ensemble du code nécessaire à l'extraction ici\n",
    "tags = []\n",
    "\n",
    "for tag in repo.tags:\n",
    "    if re.search(\"^broadleaf-[0-9].[0-9].0-GA$\", str(tag)) and not os.path.exists(f'class_{tag}.csv'):\n",
    "        repo.git.checkout(tag)\n",
    "        subprocess.run([\"java\", \"-jar\", \"ck.jar\", \"..\" + os.sep + \"BroadleafCommerce\"])\n",
    "        os.rename('class.csv', f'class_{tag}.csv')\n",
    "        os.remove('field.csv')\n",
    "        os.remove('method.csv')\n",
    "        os.remove('variable.csv')\n",
    "\n",
    "os.chdir(wd_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utilisation du classifieur de développeurs (Random Forest)\n",
    " \n",
    "Nous allons maintenant utiliser le classifieur de développeurs sauvegardé sous le nom \"classifier_rf.pkl\". \n",
    "Pour cela nous allons charger le classifieur à l'aide de <code> joblib.load </code> ([documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.load.html))\n",
    "\n",
    "2. Nous allons utiliser les métriques (23) associées à des développeurs, celles-ci sont stockées dans le dossier <code> metrics_by_dev </code>. Chaque fichier de ce dossier est nommé en fonction de la version sur laquelle les métriques ont été extraites. Nous allons donc itérer sur la **liste de ces fichiers ordonnée par ordre alphanumérique**. \n",
    "\n",
    "4. Pour chaque fichier CSV, l'ouvrir avec Pandas en tant que Dataframe via la fonction : <code> pd.read_csv </code> ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))\n",
    "\n",
    "3. Ces métriques sont à l'état \"brut\" dans les fichiers, c'est-à-dire qu'elles ont des échelles et des unités différentes. Le classifieur Random Forest que nous avons entrainé lui, ne travaille qu'avec des variables comprises dans [-1;1]. Ici, il va donc falloir faire une mise à l'échelle des variables à l'aide d'un scaler de Scikit-Learn : <code> MinMaxScaler </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)). De plus, afin de réduire les écarts de valeurs sur certaines variables nous allons appliquer un logarithme sur 11 de ces dernières à l'aide de la fonction  <code> log_dataframe </code> de ce Notebook.\n",
    "\n",
    "5. Prédire ensuite la catégorie des développeurs (\"NSSE\" ou \"SSE\") puis la stocker dans le dictionnaire <code> dict_classified_dev </code>. Faire un affichage à l'aide print pour visualiser l'évolution du nombre de dévoloppeurs dans chaque catégorie au fur et à mesure des versions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour la version \"1.6.0\" :\n",
      "Il y a eu 1 développeurs SSE\n",
      "Il y a eu 3 développeurs NSSE\n",
      "\n",
      "Pour la version \"2.0.0\" :\n",
      "Il y a eu 6 développeurs SSE\n",
      "Il y a eu 2 développeurs NSSE\n",
      "\n",
      "Pour la version \"2.1.0\" :\n",
      "Il y a eu 6 développeurs SSE\n",
      "Il y a eu 2 développeurs NSSE\n",
      "\n",
      "Pour la version \"2.2.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 3 développeurs NSSE\n",
      "\n",
      "Pour la version \"2.3.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 3 développeurs NSSE\n",
      "\n",
      "Pour la version \"2.4.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 3 développeurs NSSE\n",
      "\n",
      "Pour la version \"3.0.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 4 développeurs NSSE\n",
      "\n",
      "Pour la version \"3.1.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 9 développeurs NSSE\n",
      "\n",
      "Pour la version \"4.0.0\" :\n",
      "Il y a eu 7 développeurs SSE\n",
      "Il y a eu 21 développeurs NSSE\n",
      "\n",
      "Pour la version \"4.1.0\" :\n",
      "Il y a eu 8 développeurs SSE\n",
      "Il y a eu 24 développeurs NSSE\n",
      "\n",
      "Pour la version \"5.0.0\" :\n",
      "Il y a eu 11 développeurs SSE\n",
      "Il y a eu 21 développeurs NSSE\n",
      "\n",
      "Pour la version \"5.1.0\" :\n",
      "Il y a eu 12 développeurs SSE\n",
      "Il y a eu 23 développeurs NSSE\n",
      "\n",
      "Pour la version \"5.2.0\" :\n",
      "Il y a eu 12 développeurs SSE\n",
      "Il y a eu 29 développeurs NSSE\n",
      "\n",
      "Pour la version \"6.0.0\" :\n",
      "Il y a eu 14 développeurs SSE\n",
      "Il y a eu 37 développeurs NSSE\n",
      "\n",
      "Pour la version \"6.1.0\" :\n",
      "Il y a eu 15 développeurs SSE\n",
      "Il y a eu 41 développeurs NSSE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Documents\\Cours\\IA pour GL\\TP-Master-MTP-GL-IA4GL\\venv\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dict_classified_dev = {'SSE' : [], 'NSSE' : []}\n",
    "list_versions = []\n",
    "\n",
    "#Placer la suite du code ici\n",
    "#%%\n",
    "\n",
    "def addFromDicoToList(dico, prediction, version):\n",
    "    count_sse_dev = 0\n",
    "    count_nsse_dev = 0\n",
    "    for i in range(0, len(prediction)):\n",
    "        if prediction[i] == \"SSE\":\n",
    "            count_sse_dev += 1\n",
    "        elif prediction[i] == \"NSSE\":\n",
    "            count_nsse_dev += 1\n",
    "    pair_sse = (version.split(\"-\")[1], count_sse_dev)\n",
    "    pair_nsse = (version.split(\"-\")[1], count_nsse_dev)\n",
    "    dico[\"SSE\"].append(pair_sse)\n",
    "    dico[\"NSSE\"].append(pair_nsse)\n",
    "\n",
    "\n",
    "def orderDico(dico):\n",
    "    dico[\"SSE\"] = orderTuples(tupleList=dico[\"SSE\"])\n",
    "    dico[\"NSSE\"] = orderTuples(tupleList=dico[\"NSSE\"])\n",
    "\n",
    "\n",
    "def orderTuples(tupleList):\n",
    "    return sorted(tupleList, key=lambda tup: tup[0])\n",
    "\n",
    "#%%\n",
    "def printDevs(dico, versions):\n",
    "    for i in range(0, versions):\n",
    "        currentdevs = dico[\"SSE\"][i]\n",
    "        print(\"Pour la version \\\"\" + str(currentdevs[0]) + \"\\\" :\")\n",
    "        print(\"Il y a eu \" + str(currentdevs[1]) + \" développeurs SSE\")\n",
    "        currentdevs = dico[\"NSSE\"][i]\n",
    "        print(\"Il y a eu \" + str(currentdevs[1]) + \" développeurs NSSE\\n\")\n",
    "\n",
    "#%%\n",
    "\n",
    "dict_classified_dev = {'SSE': [], 'NSSE': []}\n",
    "list_versions = []\n",
    "classifier = joblib.load(\"classifier_rf.pkl\")\n",
    "#Placer la suite du code ici\n",
    "scale = MinMaxScaler(feature_range=(-1, 1))\n",
    "evolution = {}\n",
    "versions_count = 0\n",
    "for file in os.listdir(\".\" + os.sep + \"metrics_by_dev\"):\n",
    "    versions_count += 1\n",
    "    sse_dev = []\n",
    "    nsse_dev = []\n",
    "    df = pd.read_csv(\".\" + os.sep + \"metrics_by_dev\" + os.sep + file)\n",
    "    delete_unused_columns(df)\n",
    "    log_dataframe(df)\n",
    "    df = pd.DataFrame(scale.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "    prediction = classifier.predict(df)\n",
    "    addFromDicoToList(dico=dict_classified_dev, prediction=prediction, version=file.split(\"_\")[1])\n",
    "orderDico(dico=dict_classified_dev)\n",
    "printDevs(dico=dict_classified_dev, versions=versions_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Extraction du nombre total de lignes de code depuis les fichiers CSV\n",
    "\n",
    "Nous avons classé les développeurs par catégorie pour chaque version de BroadleafCommerce. \n",
    "L'étape suivante est d'extraire le nombre total de ligne de code pour chaque version de BroadleafCommerce. Pour cela chacun des fichiers triés par ordre alphanumérique croissant doit être ouvert avec Pandas. Vous devez ensuite faire la somme de la colonne \"loc\" des fichiers et l'ajouter à la liste <code> loc_by_versions </code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78450, 77640, 100686, 101778, 105371, 108435, 108459, 92314, 102533, 121023, 127584, 131071, 127385, 134819, 140862, 144383, 150338]\n"
     ]
    }
   ],
   "source": [
    "#Liste où ajouter les loc de chaque version \n",
    "loc_by_versions = []\n",
    "\n",
    "for file in sorted(os.listdir(\".\" + os.sep + \"ck_metrics\")):\n",
    "    if file == \"ck.jar\":\n",
    "        continue\n",
    "    nb_codelines = 0\n",
    "    df = pd.read_csv(\".\" + os.sep + \"ck_metrics\" + os.sep + file)\n",
    "    codelines = df[\"loc\"]\n",
    "    for i in codelines:\n",
    "        nb_codelines += i\n",
    "    loc_by_versions.append(nb_codelines)\n",
    "print(loc_by_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Tracé du graphique du nombre de développeurs SSE et nombre de lignes de code par version de BroadleafCommerce\n",
    "\n",
    "L'objectif ici est de tracer à l'aide du package matplotlib ([documentation](https://matplotlib.org/stable/contents.html)) un graphique à 3 axes comme montré dans la figure d'exemple ci-dessous. \n",
    "\n",
    "![Évolution du nombre de développeurs SSE vs LOC](plot_sse_vs_loc_by_version.png)\n",
    "\n",
    "En traçant cette figure vous devriez observer une particularité commune aux deux courbes, faite part de cette observation dans la case textutelle ci-desssous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'versions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/2535728193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mloc_by_versions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_by_versions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nombre de développeurs SSE et de lignes de code par version\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_classified_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SSE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tab:orange'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc_by_versions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tab:green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[1;32min\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'versions' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "#Création d'un deuxième axe Y \n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "del loc_by_versions[0]\n",
    "del loc_by_versions[len(loc_by_versions) - 1]\n",
    "fig.suptitle(\"Nombre de développeurs SSE et de lignes de code par version\")\n",
    "ax1.plot(versions, dict_classified_dev[\"SSE\"],'tab:orange')\n",
    "ax2.plot(versions, loc_by_versions,'tab:green')\n",
    "for tick in ax1.get_xticklabels():\n",
    "    tick.set_rotation(90)\n",
    "ax1.set_ylabel(\"Nombre de développeurs SSE\")\n",
    "ax2.set_ylabel(\"Nombre de lignes de codes\")\n",
    "ax2.set_xlabel(\"Version du projet\")\n",
    "ax1.set_xlabel(\"Version du projet\")\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Création d'un estimateur du nombre de développeurs expérimentés en fonction de la taille du projet (LoC)\n",
    "\n",
    "\n",
    "Nous avons maintenant l'ensemble des données permettant de créer un estimateur du nombre de développeurs expérimentés en fonction du nombre de ligne de code du projet. \n",
    "Pour ce faire, nous allons mettre en oeuvre un estimateur basé sur une régression linéaire : <code> LinearRegression </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)). Cet estimateur utilise la méthode des moindres carrés afin d'ajuster une droite d'équation *ax+b+e* où *a* est le coefficient directeur, *b* l'ordonnée à l'origine et *e* l'erreur liée aux moindres carrés. \n",
    "\n",
    "Pour cela nous allons : \n",
    "1. Créer un objet LinearRegression et l'ajuster sur <code> X </code> et <code> y </code> à l'aide de la méthode <code> fit </code>.\n",
    "2. Afficher le coefficient de régression sur <code> X </code> et <code> y </code>.\n",
    "3. Déterminer le coefficient de détermination linéaire avec la fonction <code> r2_score </code> ([documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)) qui mesure l'ajustement entre les prédiction du classifieur sur les données <code> X </code> par rapport aux sorties <code> y </code>, plus il proche de 1 meilleures sont les prédictions. \n",
    "4. Prédire le nombre de développeurs expérimentés SSE pour 150000, 180000 et 200000 lignes de code. \n",
    "5. Tracer un graphique semblable à la figure d'exemple ci-desssous :\n",
    "\n",
    "![](plot_sse_loc_prediction.png)\n",
    "\n",
    "Les points noirs sont les données déjà connues à savoir le nombre de développeurs expérimentés et le nombre de lignes de code pour chaque version. Les point rouges correspondent aux trois valeurs prédites pour 150000, 180000 et 200000 lignes. La droite bleu est la droite de régression. Pour tracer ce graphique vous pouvez vous inspirer de cet [exemple Scikit-Learn ](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py). \n",
    "\n",
    "Voilà vous êtes maintenant capable de prédire vos besoins en ressources humaines en fonction de la taille de votre projet :) ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valeurs X et y à utiliser pour entrainer et évaluer le régresseur\n",
    "X = np.array(loc_by_versions).reshape(-1,1)\n",
    "y = np.array(dict_classified_dev[\"SSE\"])\n",
    "\n",
    "#PLacer la suite du code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus\n",
    "\n",
    "Jusque là nous avons utilisé un classifieur Random Forest déjà entrainé puis sauvegardé au format Pickle (sérialisation). Dans le bloc de code ci-dessous vous trouverez le code qui a permis la création de ce classifieur. \n",
    "\n",
    "Ce code est découpé en plusieurs parties:\n",
    "\n",
    "* Ouverture du CSV contenant les développeurs et leurs métriques avec Pandas\n",
    "* Suppresssion des colonnes non utilisées pour la classification\n",
    "* Transformation des variables (logarithme et mise à l'échelle)\n",
    "* Création de l'objet permettant de générer des données synthétiques. Les données synthétiques permettent de contrebalancer le fait que nous n'ayons que peu de données dans la classe des développeurs expérimentés. \n",
    "* Création du classifieur ici un random forest\n",
    "* Évaluation du classifieur via 4-fold stratifié ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold))\n",
    "* Génération de données synthétiques sur l'ensemble du jeu de données puis entrainement du modèle\n",
    "* Sauvegarde du modèle au format pickle\n",
    "\n",
    "Vous pouvez modifier plusieurs choses qui vont influer sur la qualité de votre classifieur :  \n",
    "- Les variables utilisées. Nous utilisons ici 23 métriques. Vous pouvez en supprimer dans le dataframe Pandas et constater l'effet. \n",
    "- Le scaler utilisé, ici un MinMax pour mettre les variables dans l'intervalle [-1,1] ([documentation sur les types de scaler](https://www.datacorner.fr/feature-scaling/))\n",
    "- Le type de classifieur utilisé (ici Random Forest) et ses paramètres. Vous pouvez choisir un autre classifieur parmis ceux fournis par le package Scikit Learn ([documentation](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py))\n",
    "- L'utilisation ou non de la génération de données synthétiques. \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Returns labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    df.loc[df['job'] == \"SA\", 'job'] = \"SSE\"\n",
    "    df.loc[df['job'] != \"SSE\", 'job'] = \"NSSE\"\n",
    "\n",
    "    return df[\"job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scales data according to the scaler given as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scaling(scaler, X):\n",
    "    return scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creates synthetic data with original data using smote method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_synthetic_data(smote, X_scaled, y):\n",
    "    return smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train the classifier with synthetic data an create a classification report on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_classification_report(classifier, X_synthetic, y_synthetic, X_scaled, y):\n",
    "    classifier.fit(X_synthetic, y_synthetic)\n",
    "    print(classification_report(y, classifier.predict(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stratifiedKFold_scoring(classifier, X_scaled, y, smote = None):\n",
    "    kf = StratifiedKFold(n_splits=4, shuffle=False)#, random_state=0)\n",
    "    print(\"===> Start kfold <===\")\n",
    "    scores = {\"F1\": {\"values\" : []}, \"Recall\": {\"values\" : []},\n",
    "              \"Precision\": {\"values\" : []}, \"Balanced\\nAccuracy\" : {\"values\" : []}}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_scaled, y), 1):\n",
    "        print(\"=> Fold : \",fold)\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train = X_scaled[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X_scaled[test_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        if smote is not None:\n",
    "            X_train_synthetic, y_train_synthetic = smote.fit_resample(X_train, y_train)\n",
    "            classifier.fit(X_train_synthetic, y_train_synthetic)\n",
    "        else:\n",
    "            classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        recall = recall_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        precision = precision_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        scores[\"F1\"][\"values\"].append(f1)\n",
    "        scores[\"Recall\"][\"values\"].append(recall)\n",
    "        scores[\"Precision\"][\"values\"].append(precision)\n",
    "        scores[\"Balanced\\nAccuracy\"][\"values\"].append(accuracy)\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key][\"values\"] = np.array(scores[key][\"values\"])\n",
    "        scores[key][\"mean\"] = np.mean(scores[key][\"values\"])\n",
    "        scores[key][\"std\"] = np.std(scores[key][\"values\"])\n",
    "        scores[key][\"ci95\"] = np.std(scores[key][\"values\"]) * 2\n",
    "\n",
    "        print(key, \"mean :%0.4f\" % scores[key][\"mean\"])\n",
    "        print(key, \"std : %0.4f\" % scores[key][\"std\"])\n",
    "        print(key, \"95%% Confidence Interval +/- %0.4f\" % (scores[key][\"ci95\"]))\n",
    "        print()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start kfold <===\n",
      "=> Fold :  1\n",
      "=> Fold :  2\n",
      "=> Fold :  3\n",
      "=> Fold :  4\n",
      "F1 mean :0.7689\n",
      "F1 std : 0.0263\n",
      "F1 95% Confidence Interval +/- 0.0525\n",
      "\n",
      "Recall mean :0.7538\n",
      "Recall std : 0.0800\n",
      "Recall 95% Confidence Interval +/- 0.1601\n",
      "\n",
      "Precision mean :0.7937\n",
      "Precision std : 0.0414\n",
      "Precision 95% Confidence Interval +/- 0.0828\n",
      "\n",
      "Balanced\n",
      "Accuracy mean :0.8603\n",
      "Balanced\n",
      "Accuracy std : 0.0343\n",
      "Balanced\n",
      "Accuracy 95% Confidence Interval +/- 0.0687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_dev_anonymized.csv\")\n",
    "y = get_labels(df)\n",
    "\n",
    "delete_unused_columns(df)\n",
    "\n",
    "log_dataframe(df)\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "X = df\n",
    "X_scaled = scaling(scaler, X)\n",
    "\n",
    "#Instanciation du générateur de données synthétiques à l'aide de la méthode k-means SMOTE\n",
    "smote = KMeansSMOTE(sampling_strategy='minority', random_state=9090)\n",
    "#Création du classifieur RF\n",
    "classifier = RandomForestClassifier(criterion='gini', max_depth=None, max_features='log2', n_estimators=75, random_state=0)\n",
    "\n",
    "#Évaluation du classifieur à l'aide d'un 4-fold stratifié\n",
    "stratifiedKFold_scoring(classifier, X_scaled, y, smote = smote)\n",
    "\n",
    "#Génération de données synthétiques sur l'ensemble des données\n",
    "X_synthetic, y_synthetic = smote.fit_resample(X_scaled, y)\n",
    "#Entrainement du classifieur sur les données synthétiques\n",
    "classifier.fit(X_synthetic, y_synthetic)\n",
    "#Sauvegarde du classifieur (sérialisation) \n",
    "pickle.dump(classifier, open(\"classifier_rf.pkl\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b972025ffaeb9fad2e6c47485e66bc7f129e1b41ab4934c78195a6e21efd40ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
